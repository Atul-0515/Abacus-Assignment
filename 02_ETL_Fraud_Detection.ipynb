{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d4ff788b-4984-4290-a974-42650353b0e6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /databricks/python3/lib/python3.12/site-packages (1.6.1)\nRequirement already satisfied: imbalanced-learn in /local_disk0/.ephemeral_nfs/envs/pythonEnv-bec62abc-00d6-4e5b-862b-56acaa7827ff/lib/python3.12/site-packages (0.14.0)\nRequirement already satisfied: numpy>=1.19.5 in /databricks/python3/lib/python3.12/site-packages (from scikit-learn) (2.1.3)\nRequirement already satisfied: scipy>=1.6.0 in /databricks/python3/lib/python3.12/site-packages (from scikit-learn) (1.15.1)\nRequirement already satisfied: joblib>=1.2.0 in /databricks/python3/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\nRequirement already satisfied: threadpoolctl>=3.1.0 in /databricks/python3/lib/python3.12/site-packages (from scikit-learn) (3.5.0)\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-learn imbalanced-learn\n",
    "%restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e120d0f0-6e44-4b32-b473-5a30c1189615",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Bronze Tables...\n\n=== SILVER LAYER: DATA ENRICHMENT ===\n✅ Silver table created with 5000 enriched records\n\nSample enriched data:\n+--------+-------------+---------+--------------------+--------------------+--------+\n|claim_id|billed_amount|specialty|provider_claim_count|amount_deviation_pct|is_fraud|\n+--------+-------------+---------+--------------------+--------------------+--------+\n| C003001|      3690.81|Neurology|                 106|   -9.42524532166707|       0|\n| C003002|     21543.58| Oncology|                 116|  161.71920854175633|       0|\n| C003003|      2001.87|Neurology|                 106| -27.771445150972557|       0|\n| C003004|       3499.5|Neurology|                 100|  12.630412065097197|       0|\n| C003005|      3286.98|Neurology|                 103|   5.389043396259714|       0|\n+--------+-------------+---------+--------------------+--------------------+--------+\nonly showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: ETL - Silver Layer (Data Cleansing & Feature Engineering)\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier, IsolationForest\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Loading Bronze Tables...\")\n",
    "claims_bronze = spark.table(\"fraud_detection.claims_bronze\")\n",
    "patients = spark.table(\"fraud_detection.patients\")\n",
    "providers = spark.table(\"fraud_detection.providers\")\n",
    "\n",
    "print(\"\\n=== SILVER LAYER: DATA ENRICHMENT ===\")\n",
    "\n",
    "# Rename conflicting columns before join\n",
    "patients = patients.withColumnRenamed(\"state\", \"patient_state\")\n",
    "providers = providers.withColumnRenamed(\"state\", \"provider_state\")\n",
    "\n",
    "# Join claims with patients and providers\n",
    "claims_enriched = claims_bronze \\\n",
    "    .join(patients, \"patient_id\", \"left\") \\\n",
    "    .join(providers, \"provider_id\", \"left\")\n",
    "\n",
    "# Feature Engineering\n",
    "claims_silver = claims_enriched.withColumn(\n",
    "    \"claim_year\", F.year(F.col(\"claim_date\"))\n",
    ").withColumn(\n",
    "    \"claim_month_num\", F.month(F.col(\"claim_date\"))\n",
    ").withColumn(\n",
    "    \"claim_day_of_week\", F.dayofweek(F.col(\"claim_date\"))\n",
    ").withColumn(\n",
    "    \"amount_log\", F.log1p(F.col(\"billed_amount\"))\n",
    ")\n",
    "\n",
    "# Calculate provider-level statistics\n",
    "provider_stats = claims_silver.groupBy(\"provider_id\").agg(\n",
    "    F.count(\"claim_id\").alias(\"provider_claim_count\"),\n",
    "    F.avg(\"billed_amount\").alias(\"provider_avg_amount\"),\n",
    "    F.stddev(\"billed_amount\").alias(\"provider_stddev_amount\"),\n",
    "    F.sum(F.when(F.col(\"is_fraud\") == 1, 1).otherwise(0)).alias(\"provider_fraud_count\")\n",
    ")\n",
    "\n",
    "# Calculate patient-level statistics\n",
    "patient_stats = claims_silver.groupBy(\"patient_id\").agg(\n",
    "    F.count(\"claim_id\").alias(\"patient_claim_count\"),\n",
    "    F.avg(\"billed_amount\").alias(\"patient_avg_amount\")\n",
    ")\n",
    "\n",
    "# Join statistics back\n",
    "claims_silver = claims_silver \\\n",
    "    .join(provider_stats, \"provider_id\", \"left\") \\\n",
    "    .join(patient_stats, \"patient_id\", \"left\")\n",
    "\n",
    "# Calculate amount deviation from provider average\n",
    "claims_silver = claims_silver.withColumn(\n",
    "    \"amount_deviation_pct\",\n",
    "    F.when(F.col(\"provider_avg_amount\") > 0,\n",
    "           ((F.col(\"billed_amount\") - F.col(\"provider_avg_amount\")) / F.col(\"provider_avg_amount\")) * 100\n",
    "    ).otherwise(0)\n",
    ")\n",
    "\n",
    "# Save Silver Table\n",
    "claims_silver.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"fraud_detection.claims_silver\")\n",
    "\n",
    "print(f\"✅ Silver table created with {claims_silver.count()} enriched records\")\n",
    "print(\"\\nSample enriched data:\")\n",
    "claims_silver.select(\n",
    "    \"claim_id\", \"billed_amount\", \"specialty\", \"provider_claim_count\", \n",
    "    \"amount_deviation_pct\", \"is_fraud\"\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "93d3df0a-0c73-4b8d-8be4-58eafd1de865",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n=== GOLD LAYER: ML FRAUD DETECTION ===\nTotal claims: 5000\nKnown fraud cases: 400\n\nTraining set: 3500 claims\nTest set: 1500 claims\n\n\uD83E\uDD16 Training Random Forest Classifier...\n\n=== MODEL PERFORMANCE ===\n              precision    recall  f1-score   support\n\n      Normal       0.96      0.98      0.97      1380\n       Fraud       0.77      0.57      0.66       120\n\n    accuracy                           0.95      1500\n   macro avg       0.87      0.78      0.82      1500\nweighted avg       0.95      0.95      0.95      1500\n\n\n=== TOP 10 IMPORTANT FEATURES ===\n                 feature  importance\n8   amount_deviation_pct    0.284977\n1             amount_log    0.147584\n0          billed_amount    0.140629\n10     procedure_encoded    0.104953\n6   provider_fraud_count    0.074563\n5    provider_avg_amount    0.063078\n7    patient_claim_count    0.048826\n4   provider_claim_count    0.039367\n2        claim_month_num    0.037378\n9      specialty_encoded    0.034715\n\n\uD83D\uDD0D Running Isolation Forest for Anomaly Detection...\n\n✅ Gold table created with fraud analysis\nTotal suspicious claims: 662\nDetection rate: 13.2%\n\n=== SAMPLE SUSPICIOUS CLAIMS ===\n    claim_id  ...                                  fraud_explanation\n12   C000013  ...  ML detected (confidence: 50.03%) | Provider ha...\n48   C000049  ...  ML detected (confidence: 56.63%) | Statistical...\n49   C000050  ...                       Statistical anomaly detected\n69   C000070  ...                       Statistical anomaly detected\n112  C000113  ...                       Statistical anomaly detected\n134  C000135  ...  Statistical anomaly detected | Provider has 18...\n160  C000161  ...                       Statistical anomaly detected\n181  C000182  ...                       Statistical anomaly detected\n182  C000183  ...  ML detected (confidence: 51.90%) | Statistical...\n195  C000196  ...  Statistical anomaly detected | Amount 246% dev...\n\n[10 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: ML-Based Fraud Detection (Gold Layer)\n",
    "\n",
    "print(\"\\n=== GOLD LAYER: ML FRAUD DETECTION ===\")\n",
    "\n",
    "# Load silver data\n",
    "claims_silver_df = spark.table(\"fraud_detection.claims_silver\").toPandas()\n",
    "\n",
    "print(f\"Total claims: {len(claims_silver_df)}\")\n",
    "print(f\"Known fraud cases: {claims_silver_df['is_fraud'].sum()}\")\n",
    "\n",
    "# Feature preparation\n",
    "feature_columns = [\n",
    "    'billed_amount', 'amount_log', 'claim_month_num', 'claim_day_of_week',\n",
    "    'provider_claim_count', 'provider_avg_amount', 'provider_fraud_count',\n",
    "    'patient_claim_count', 'amount_deviation_pct'\n",
    "]\n",
    "\n",
    "# Handle missing values\n",
    "claims_silver_df[feature_columns] = claims_silver_df[feature_columns].fillna(0)\n",
    "\n",
    "# Encode categorical features\n",
    "le_specialty = LabelEncoder()\n",
    "le_procedure = LabelEncoder()\n",
    "\n",
    "claims_silver_df['specialty_encoded'] = le_specialty.fit_transform(claims_silver_df['specialty'].fillna('Unknown'))\n",
    "claims_silver_df['procedure_encoded'] = le_procedure.fit_transform(claims_silver_df['procedure_code'].fillna('Unknown'))\n",
    "\n",
    "# Final feature set\n",
    "ml_features = feature_columns + ['specialty_encoded', 'procedure_encoded']\n",
    "X = claims_silver_df[ml_features]\n",
    "y = claims_silver_df['is_fraud']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"\\nTraining set: {len(X_train)} claims\")\n",
    "print(f\"Test set: {len(X_test)} claims\")\n",
    "\n",
    "# Train Random Forest Classifier\n",
    "print(\"\\n\uD83E\uDD16 Training Random Forest Classifier...\")\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    min_samples_split=20,\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = rf_model.predict(X_test)\n",
    "y_pred_proba = rf_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"\\n=== MODEL PERFORMANCE ===\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Normal', 'Fraud']))\n",
    "\n",
    "# Feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': ml_features,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\n=== TOP 10 IMPORTANT FEATURES ===\")\n",
    "print(feature_importance.head(10))\n",
    "\n",
    "# Add predictions to full dataset\n",
    "claims_silver_df['fraud_score'] = rf_model.predict_proba(X)[:, 1]\n",
    "claims_silver_df['ml_prediction'] = rf_model.predict(X)\n",
    "\n",
    "# Anomaly Detection using Isolation Forest (unsupervised)\n",
    "print(\"\\n\uD83D\uDD0D Running Isolation Forest for Anomaly Detection...\")\n",
    "iso_forest = IsolationForest(contamination=0.08, random_state=42)\n",
    "claims_silver_df['anomaly_score'] = iso_forest.fit_predict(X)\n",
    "claims_silver_df['is_anomaly'] = (claims_silver_df['anomaly_score'] == -1).astype(int)\n",
    "\n",
    "# Combined fraud flag\n",
    "claims_silver_df['final_fraud_flag'] = (\n",
    "    (claims_silver_df['is_fraud'] == 1) | \n",
    "    (claims_silver_df['ml_prediction'] == 1) | \n",
    "    (claims_silver_df['is_anomaly'] == 1)\n",
    ").astype(int)\n",
    "\n",
    "# Generate fraud explanation\n",
    "def generate_fraud_explanation(row):\n",
    "    reasons = []\n",
    "    \n",
    "    if row['fraud_type'] is not None:\n",
    "        reasons.append(f\"Known fraud: {row['fraud_reason']}\")\n",
    "    \n",
    "    if row['ml_prediction'] == 1:\n",
    "        reasons.append(f\"ML detected (confidence: {row['fraud_score']:.2%})\")\n",
    "    \n",
    "    if row['is_anomaly'] == 1:\n",
    "        reasons.append(\"Statistical anomaly detected\")\n",
    "    \n",
    "    if abs(row['amount_deviation_pct']) > 200:\n",
    "        reasons.append(f\"Amount {row['amount_deviation_pct']:.0f}% deviation from provider average\")\n",
    "    \n",
    "    if row['provider_fraud_count'] > 5:\n",
    "        reasons.append(f\"Provider has {row['provider_fraud_count']} known fraud cases\")\n",
    "    \n",
    "    return \" | \".join(reasons) if reasons else \"No fraud detected\"\n",
    "\n",
    "claims_silver_df['fraud_explanation'] = claims_silver_df.apply(generate_fraud_explanation, axis=1)\n",
    "\n",
    "# Select columns for Gold table\n",
    "gold_columns = [\n",
    "    'claim_id', 'patient_id', 'provider_id', 'claim_date', 'procedure_code',\n",
    "    'diagnosis_code', 'billed_amount', 'specialty', 'patient_name', 'provider_name',\n",
    "    'is_fraud', 'fraud_type', 'ml_prediction', 'fraud_score', 'is_anomaly',\n",
    "    'final_fraud_flag', 'fraud_explanation', 'claim_month', 'amount_deviation_pct',\n",
    "    'provider_fraud_count'\n",
    "]\n",
    "\n",
    "claims_gold_df = claims_silver_df[gold_columns]\n",
    "\n",
    "# Save to Gold table\n",
    "claims_gold_spark = spark.createDataFrame(claims_gold_df)\n",
    "claims_gold_spark.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"fraud_detection.claims_gold\")\n",
    "\n",
    "print(f\"\\n✅ Gold table created with fraud analysis\")\n",
    "print(f\"Total suspicious claims: {claims_gold_df['final_fraud_flag'].sum()}\")\n",
    "print(f\"Detection rate: {claims_gold_df['final_fraud_flag'].sum() / len(claims_gold_df) * 100:.1f}%\")\n",
    "\n",
    "# Show sample suspicious claims\n",
    "print(\"\\n=== SAMPLE SUSPICIOUS CLAIMS ===\")\n",
    "suspicious = claims_gold_df[claims_gold_df['final_fraud_flag'] == 1].head(10)\n",
    "print(suspicious[['claim_id', 'specialty', 'billed_amount', 'fraud_score', 'fraud_explanation']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "899bea7f-23d2-4651-ad31-8783a5289066",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "02_ETL_Fraud_Detection",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}